{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slots Vacany According to Bayes Theorem\n",
    "Very often, we'll want consider more than one random variable at a time. \n",
    "For instance, we may want to model the relationship between diseases and symptoms.\n",
    "Given a disease and symptom, say 'flu' and 'cough', \n",
    "either may or may not occur in a patient with some probability.\n",
    "While we hope that the probability of both would be close to zero,\n",
    "we may want to estimate these probabilities and their relationships to each other\n",
    "so that we may apply our inferences to effect better medical care.\n",
    "\n",
    "As a more complicated example, images contain millions of pixels, thus millions of random variables. \n",
    "And in many cases images will come with a label, identifying objects in the image.\n",
    "We can also think of the label as a random variable.\n",
    "We can even get crazy and think of all the metadata as random variables\n",
    "such as location, time, aperture, focal length, ISO, focus distance, camera type, etc.\n",
    "All of these are random variables that occur jointly. \n",
    "When we deal with multiple random variables, \n",
    "there are several quantities of interest.\n",
    "The first is called the joint distribution $\\Pr(A, B)$. \n",
    "Given any elements $a$ and $b$,\n",
    "the joint distribution lets us answer,\n",
    "what is the probability that $A=a$ and $B=b$ simulataneously?\n",
    "It might be clear that for any values $a$ and $b$, $\\Pr(A,B) \\leq \\Pr(A=a)$. \n",
    "\n",
    "This has to be the case, since for $A$ and $B$ to happen, \n",
    "$A$ has to happen *and* $B$ also has to happen (and vice versa). \n",
    "Thus $A,B$ cannot be more likely than $A$ or $B$ individually. \n",
    "This brings us to an interesting ratio: $0 \\leq \\frac{\\Pr(A,B)}{\\Pr(A)} \\leq 1$. \n",
    "We call this a **conditional probability** and denote it by $\\Pr(B|A)$, \n",
    "the probability that $B$ happens, provided that $A$ has happened. \n",
    "\n",
    "Using the definition of conditional probabilities, \n",
    "we can derive one of the most useful and celebrated equations in statistics - Bayes' theorem. \n",
    "It goes as follows: By construction, we have that $\\Pr(A, B) = \\Pr(B|A) \\Pr(A)$. \n",
    "By symmetry, this also holds for $\\Pr(A,B) = \\Pr(A|B) \\Pr(B)$. \n",
    "Solving for one of the conditional variables we get:\n",
    "$$\\Pr(A|B) = \\frac{\\Pr(B|A) \\Pr(A)}{\\Pr(B)}$$\n",
    "\n",
    "This is very useful if we want to infer one thing from another, \n",
    "say cause and effect but we only know the properties in the reverse direction. \n",
    "One important operation that we need to make this work is **marginalization**, i.e., \n",
    "the operation of determining $\\Pr(A)$ and $\\Pr(B)$ from $\\Pr(A,B)$.\n",
    "We can see that the probability of seeing $A$ amounts to accounting \n",
    "for all possible choices of $B$ and aggregating the joint probabilities over all of them, i.e. \n",
    "\n",
    "$$\\Pr(A) = \\sum_{B'} \\Pr(A,B') \\text{ and } \\Pr(B) = \\sum_{A'} \\Pr(A',B)$$\n",
    "\n",
    "A really useful property to check is for **dependence** and **independence**. \n",
    "Independence is when the occurrence of one event does not influence the occurrence of the other.\n",
    "In this case $\\Pr(B|A) = \\Pr(B)$. Statisticians typically use $A \\perp\\!\\!\\!\\perp B$ to express this. \n",
    "From Bayes Theorem it follows immediately that also $\\Pr(A|B) = \\Pr(A)$. \n",
    "In all other cases we call $A$ and $B$ dependent. \n",
    "For instance, two successive rolls of a dice are independent. \n",
    "On the other hand, the position of a light switch and the brightness in the room are not \n",
    "(they are not perfectly deterministic, though, \n",
    "since we could always have a broken lightbulb, power failure, or a broken switch). \n",
    "\n",
    "## Dealing With Our Data\n",
    "Assume that our model is really accurate (which it's true).\n",
    "It fails with 2% probability \n",
    "if the slot is vacant and the predictions returns that it's occupied,\n",
    "Or it fails with 1% probability if the slot is occupied and the predictions returns that it's vacant.\n",
    "\n",
    "We use $P$ to indicate the prediction and $T$ to denote the slot status,i i.e. the true label.\n",
    "Written as a table the outcome $\\Pr(P|T)$ looks as follows:\n",
    "\n",
    "|                          | Slot is vacant (T = 0) | Slot is occupied (T = 1) |\n",
    "|:-------------------------|-----------------------:|-------------------------:|\n",
    "|Predicted vacant (P = 0)  | 0.98                   | 0.01                     |\n",
    "|Predicted occupied (P = 1)| 0.02                   | 0.99                     |\n",
    "\n",
    "Note that the column sums are all one (but the row sums aren't), \n",
    "since the conditional probability needs to sum up to $1$, just like the probability. \n",
    "Let us work out the probability of the slot being vacant if the prediction say that it's vacant. \n",
    "Obviously this is going to depend on how common the slot is vacant, since it affects the number of false alarms.\n",
    "\n",
    "### Example 1 (busy parking lot)\n",
    "Assume that we are in a busy parking lot when only *10% of the time the slot is vacant*, e.g. $\\Pr(\\text{slot is vacant}) = 0.1$.\n",
    "\n",
    "To apply Bayes Theorem we need to determine \n",
    "\n",
    "$$\\Pr(\\text{predicted vacant}) = \\Pr(P=0|T=0) \\Pr(T=0) + \\Pr(P=0|T=1) \\Pr(T=1) = 0.98 \\cdot 0.1 +0.01 \\cdot 0.9 = 0.107$$\n",
    "\n",
    "So $\\Pr(T=0) = 0.1$ and $\\Pr(P=0) = 0.107$.\n",
    "\n",
    "Hence we get $$\\Pr(T = 0|P = 0) = \\frac{\\Pr(P=0|T=0) \\Pr(T=0)}{\\Pr(P=0)} = \\frac{0.98 \\cdot 0.1}{0.107} = 0.915$$\n",
    "In other words, there's only a 91.5% chance that the slot is actually vacant, despite using a model that is around 98-99% accurate!.\n",
    "\n",
    "### Example 2 (not so busy parking lot)\n",
    "Now assume that the parking lot is quite empty, around *95% of the time the slot is vacant*, e.g. $\\Pr(\\text{slot is vacant}) = 0.95$.\n",
    "\n",
    "To apply Bayes Theorem we need to determine \n",
    "\n",
    "$$\\Pr(\\text{predicted vacant}) = \\Pr(P=0|T=0) \\Pr(T=0) + \\Pr(P=0|T=1) \\Pr(T=1) = 0.98 \\cdot 0.95 +0.01 \\cdot 0.05 = 0.9315$$\n",
    "\n",
    "So $\\Pr(T=0) = 0.95$ and $\\Pr(P=0) = 0.9315$.\n",
    "\n",
    "Hence we get $$\\Pr(T = 0|P = 0) = \\frac{\\Pr(P=0|T=0) \\Pr(T=0)}{\\Pr(P=0)} = \\frac{0.98 \\cdot 0.95}{0.9315} = 0.9994$$\n",
    "There's a 99.9% chance that the slot is actually vacant, which is great!.\n",
    "\n",
    "### Example 3 (50/50 parking lot)\n",
    "Now assume that around *50% of the time the slot is vacant*, e.g. $\\Pr(\\text{slot is vacant}) = 0.50$.\n",
    "\n",
    "To apply Bayes Theorem we need to determine \n",
    "\n",
    "$$\\Pr(\\text{predicted vacant}) = \\Pr(P=0|T=0) \\Pr(T=0) + \\Pr(P=0|T=1) \\Pr(T=1) = 0.98 \\cdot 0.50 +0.01 \\cdot 0.50 = 0.495$$\n",
    "\n",
    "So $\\Pr(T=0) = 0.50$ and $\\Pr(P=0) = 0.495$.\n",
    "\n",
    "Hence we get $$\\Pr(T = 0|P = 0) = \\frac{\\Pr(P=0|T=0) \\Pr(T=0)}{\\Pr(P=0)} = \\frac{0.98 \\cdot 0.50}{0.495} = 0.9898$$\n",
    "There's a 98.98% chance that the slot is actually vacant, which is quite great!. \n",
    "\n",
    "\n",
    "## What's The Point With This Example?\n",
    "I don't know, maybe that in the future when we deal with slots recommendation (for navigation), we should remember to take into account also the $\\Pr(\\text{slot is vacant})$, which can be easily calculated given slot history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets plot the outcome probability given different $\\Pr(T=0)$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Set default figure size\n",
    "matplotlib.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pr_T = np.linspace(0.00, 1.0, 101)\n",
    "Pr_P = 0.98 * Pr_T + 0.01 * (1 - Pr_T)\n",
    "prob = (0.98 * Pr_T) / Pr_P\n",
    "\n",
    "plt.plot(Pr_T, prob)\n",
    "plt.xlabel('Pr(slot is vacant)')\n",
    "plt.ylabel('Pr(slot is vacant | Predicted vacant)')\n",
    "plt.ylim([0.85, 1.0])\n",
    "plt.plot([0, 1], [0.99, 0.99], 'r-', lw = 2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for small values of $\\Pr(T=0)$ the outcome probability isn't very promising..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
